{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "#from lightgbm import LGBMRegressor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import json\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from random import choice\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de vista minable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>qty_adopciones_1M</th>\n",
       "      <th>qty_adopciones_3M</th>\n",
       "      <th>qty_adopciones_6M</th>\n",
       "      <th>qty_adopciones_9M</th>\n",
       "      <th>mes</th>\n",
       "      <th>anio</th>\n",
       "      <th>qty_dias_ultima_adopcion</th>\n",
       "      <th>qty_dias_ultimo_page_ingreso</th>\n",
       "      <th>snapshot_mes_x</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_adoption_preferencia_CONNECTION_SPEED_2.0</th>\n",
       "      <th>ratio_adoption_preferencia_CONNECTION_SPEED_3.0</th>\n",
       "      <th>ratio_adoption_interes_CONNECTION_SPEED</th>\n",
       "      <th>snapshot_mes</th>\n",
       "      <th>ratio_adoption_preferencia_ON_SITE_SEARCH_TERM_1</th>\n",
       "      <th>ratio_adoption_preferencia_ON_SITE_SEARCH_TERM_1.0</th>\n",
       "      <th>ratio_adoption_preferencia_ON_SITE_SEARCH_TERM_63.0</th>\n",
       "      <th>ratio_adoption_preferencia_ON_SITE_SEARCH_TERM_89.0</th>\n",
       "      <th>ratio_adoption_interes_ON_SITE_SEARCH_TERM</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30584 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  qty_adopciones_1M  qty_adopciones_3M  qty_adopciones_6M  \\\n",
       "0        0                0.0                0.0                0.0   \n",
       "1        1                0.0                0.0                0.0   \n",
       "2        2                0.0                0.0                0.0   \n",
       "3        3                0.0                0.0                0.0   \n",
       "4        4                0.0                0.0                0.0   \n",
       "\n",
       "   qty_adopciones_9M  mes  anio  qty_dias_ultima_adopcion  \\\n",
       "0                0.0  0.0   0.0                       0.0   \n",
       "1                0.0  0.0   0.0                       0.0   \n",
       "2                0.0  0.0   0.0                       0.0   \n",
       "3                0.0  0.0   0.0                       0.0   \n",
       "4                0.0  0.0   0.0                       0.0   \n",
       "\n",
       "   qty_dias_ultimo_page_ingreso  snapshot_mes_x   ...    \\\n",
       "0                             0               9   ...     \n",
       "1                             0               9   ...     \n",
       "2                             2               9   ...     \n",
       "3                             2               9   ...     \n",
       "4                             3               9   ...     \n",
       "\n",
       "  ratio_adoption_preferencia_CONNECTION_SPEED_2.0  \\\n",
       "0                                          -999.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                          -999.0   \n",
       "4                                             0.0   \n",
       "\n",
       "   ratio_adoption_preferencia_CONNECTION_SPEED_3.0  \\\n",
       "0                                              0.0   \n",
       "1                                           -999.0   \n",
       "2                                              0.0   \n",
       "3                                           -999.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   ratio_adoption_interes_CONNECTION_SPEED snapshot_mes  \\\n",
       "0                                      0.0            9   \n",
       "1                                      0.0            9   \n",
       "2                                      0.0            9   \n",
       "3                                      0.0            9   \n",
       "4                                      0.0            9   \n",
       "\n",
       "   ratio_adoption_preferencia_ON_SITE_SEARCH_TERM_1  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               0.0   \n",
       "3                                               0.0   \n",
       "4                                               0.0   \n",
       "\n",
       "   ratio_adoption_preferencia_ON_SITE_SEARCH_TERM_1.0  \\\n",
       "0                                             -999.0    \n",
       "1                                             -999.0    \n",
       "2                                             -999.0    \n",
       "3                                             -999.0    \n",
       "4                                             -999.0    \n",
       "\n",
       "   ratio_adoption_preferencia_ON_SITE_SEARCH_TERM_63.0  \\\n",
       "0                                             -999.0     \n",
       "1                                             -999.0     \n",
       "2                                             -999.0     \n",
       "3                                             -999.0     \n",
       "4                                             -999.0     \n",
       "\n",
       "   ratio_adoption_preferencia_ON_SITE_SEARCH_TERM_89.0  \\\n",
       "0                                             -999.0     \n",
       "1                                             -999.0     \n",
       "2                                             -999.0     \n",
       "3                                             -999.0     \n",
       "4                                             -999.0     \n",
       "\n",
       "   ratio_adoption_interes_ON_SITE_SEARCH_TERM  target  \n",
       "0                                         0.0       0  \n",
       "1                                         0.0       0  \n",
       "2                                         0.0       0  \n",
       "3                                         0.0       0  \n",
       "4                                         0.0       0  \n",
       "\n",
       "[5 rows x 30584 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/dataset_final.csv\")\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['FEC_EVENT_MAX' 'FEC_EVENT_MENOS_7D'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-02c953edd11f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FEC_EVENT_MAX'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FEC_EVENT_MENOS_7D'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/pythonenv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3695\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3696\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3697\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3699\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m~/.virtualenvs/pythonenv/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3111\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pythonenv/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3141\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3143\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3144\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pythonenv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4403\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4404\u001b[0;31m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[1;32m   4405\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['FEC_EVENT_MAX' 'FEC_EVENT_MENOS_7D'] not found in axis\""
     ]
    }
   ],
   "source": [
    "dataset = dataset.drop(['FEC_EVENT_MAX','FEC_EVENT_MENOS_7D'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.replace(np.inf, 999)\n",
    "dataset = dataset.fillna(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = dataset.drop(['target'], axis = 1)\n",
    "train_labels = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidationSelector(X, y, folds):  \n",
    "    skf = StratifiedKFold(n_splits=folds)\n",
    "    return skf.split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainWithCrossValidation(kfold, base, learner):    \n",
    "    # kfolds are the folds that return crossValidationSelector\n",
    "    # base is the dataset\n",
    "    # learner is the model with the best parameters\n",
    "    proba = pd.DataFrame()\n",
    "    preds = pd.DataFrame()\n",
    "    X, y = base.drop(base.columns[-1], axis=1), base.iloc[:,-1] \n",
    "    \n",
    "    for train_index, test_index in kfold:\n",
    "#    for train_index, test_index in kfold.split(X, y):\n",
    "        X_train, X_test = X.loc.__getitem__(train_index), X.loc.__getitem__(test_index)\n",
    "        y_train, y_test = y.loc.__getitem__(train_index), y.loc.__getitem__(test_index)    \n",
    "        auxTest = X_test.copy()\n",
    "        X_train = X_train.values.astype(np.float32, order=\"C\")\n",
    "        X_test = X_test.values.astype(np.float32, order=\"C\")\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(np.r_[X_train, X_test])\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "        probabilidades, predicciones = train(learner, X_train, y_train, X_test, y_test)     \n",
    "        auxTest['prob'] = probabilidades\n",
    "        proba = pd.concat([proba, auxTest[['prob']]])\n",
    "        \n",
    "        auxTest['pred'] = predicciones\n",
    "        preds = pd.concat([preds, auxTest[['pred']]])\n",
    "        \n",
    "    #fold_importance_df = pd.DataFrame()\n",
    "    #fold_importance_df[\"feature\"] = X.columns\n",
    "    #fold_importance_df[\"importance\"] = learner.feature_importance()\n",
    "    #feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    return proba, preds, learner\n",
    "\n",
    "#####################################################################################################################\n",
    "\n",
    "\n",
    "def train(learner, X_train, y_train, X_test, y_test, esr=20):\n",
    "    mask = y_test.isin(y_train.unique()).values\n",
    "    learner.fit(X_train, y_train,\n",
    "                eval_set=[(X_test, y_test),\n",
    "                          (X_test[mask], y_test[mask])\n",
    "                          ],\n",
    "                early_stopping_rounds=esr,\n",
    "                verbose=True)\n",
    "    #n_estimators = learner.best_iteration\n",
    "    n_estimators = 10000\n",
    "    probs = learner.predict_proba(X_test, ntree_limit=n_estimators)[:, -1]\n",
    "    pred = learner.predict(X_test, ntree_limit=n_estimators)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return probs, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    accuracy = metrics.accuracy_score(test_labels, predictions)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Random search de los mejores parametros</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se le pasa el modelo, un grid de parametros, los features y labels para entrenar\n",
    "def trainRandomGrid(candidate, random_grid, train_features, train_labels):\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    model = candidate\n",
    "    # Random search of parameters, using 3 fold cross validations\n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_random = RandomizedSearchCV(estimator = model, param_distributions = random_grid, n_iter = 5, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "    # Fit the random search model\n",
    "    \n",
    "    rf_random.fit(X = train_features, y= train_labels)\n",
    "    \n",
    "    # We can view the best parameters from fitting the random search\n",
    "    # rf_random.best_params_\n",
    "\n",
    "    return rf_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Grid search a partir de Random search en busqueda de los mejores parametros</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGrid(candidate, param_grid, train_features, train_labels):\n",
    "    # Create a based model\n",
    "    model = candidate\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(estimator = model, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "    ######## TRAIN GRID SELECTOR #######\n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(train_features, train_labels)\n",
    "    #grid_search.best_params_\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecucion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Buscamos los mejores parametros de manera random para achicar el espacio de busqueda</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lbatlle/.virtualenvs/pythonenv/lib/python3.7/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 2 is smaller than n_iter=5. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LGBMClassifier()\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.05],\n",
    "    'num_leaves': [10],\n",
    "    'boosting_type' : ['gbdt','dart'],\n",
    "    'objective' : ['binary'],\n",
    "    'max_depth' : [5],\n",
    "    'random_state' : [501], \n",
    "    'colsample_bytree' : [0.5],\n",
    "    'subsample' : [0.5],\n",
    "    'min_split_gain' : [0.01],\n",
    "    'min_data_in_leaf':[10],\n",
    "    'metric':['auc']\n",
    "    }\n",
    "\n",
    "\n",
    "randomGrid = trainRandomGrid(model, params, train_features, train_labels)\n",
    "best_random = randomGrid.best_estimator_\n",
    "\n",
    "#Print best paramas and accuracy\n",
    "best_random = randomGrid.best_estimator_\n",
    "random_accuracy = evaluate(best_random, train_features, train_labels)\n",
    "\n",
    "print(randomGrid.best_estimator_)\n",
    "print(random_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Ahora con un espacio de busqueda mas acotado realizamos una busqueda de mejores paramestros de manera exhaustiva</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params = { \"params\": {\n",
    "                        'learning_rate': [0.05],\n",
    "                        'num_leaves': [90,200,500],\n",
    "                        'boosting_type' : ['gbdt','dart'],\n",
    "                        'objective' : ['binary'],\n",
    "                        'max_depth' : [9,10,11,15,20,25],\n",
    "                        'random_state' : [501,600,750], \n",
    "                        'colsample_bytree' : [0.5,0.7,0.10,0.20],\n",
    "                        'subsample' : [0.5,0.7,0.3,0.1,0.9],\n",
    "                        'min_split_gain' : [0.001,0.01,0.05,0.10],\n",
    "                        'min_child_samples' : [0.001,0.005,0.010,0.0001],\n",
    "                        'min_data_in_leaf':[10],\n",
    "                        'metric':['auc']\n",
    "                        }\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = new_params[\"params\"]\n",
    "bestGrid = trainGrid(model, params, train_features, train_labels)\n",
    "\n",
    "#Evaluate the model\n",
    "best_model = bestGrid.best_estimator_\n",
    "accuracy = evaluate(best_model, train_features, train_labels)\n",
    "\n",
    "#Print best paramas and accuracy\n",
    "print(bestGrid.best_estimator_)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Teniendo los mejores hiperparametros procedemos a entrenar el modelo </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier()\n",
    "\n",
    "kfolds = crossValidationSelector(train_features, train_labels, 5)\n",
    "proba, preds, model = trainWithCrossValidation(kfolds, dataset, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Vemos la importancia de las variables</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (feature_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,25))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Por ultimo vemos las metricas resultantes</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AUROC ###\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np.asarray(dataset.target), np.asarray(preds))\n",
    "m = {\"auc\": metrics.roc_auc_score(np.asarray(dataset.target), np.asarray(preds)),\n",
    "                    \"tpr\": tpr,\n",
    "                    \"fpr\": fpr                        \n",
    "                    }    \n",
    "\n",
    "    \n",
    "label = 'ROC curve for {0}:'.format(m)\n",
    "plt.plot(m['fpr'], m['tpr'], label=label+'AUC={0:0.2f}'.format(m['auc']))\n",
    "\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "plt.grid(True)\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MATRIZ DE CONFUSION ###\n",
    "\n",
    "confusion_mc = confusion_matrix(train_labels,preds)\n",
    "df_cm = pd.DataFrame(confusion_mc)\n",
    "\n",
    "plt.figure(figsize=(5.5,4))\n",
    "sns.heatmap(df_cm, annot=True)\n",
    "plt.title('XGBoost RBF Kernel \\nAccuracy: {0:.3f}'\n",
    "        .format(accuracy_score(train_labels,preds)))\n",
    "plt.ylabel('True label')\n",
    "plt.ylabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
